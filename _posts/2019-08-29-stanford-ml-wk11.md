---
layout: post
title:  "斯坦福机器学习课程笔记（Week 11）"
date:   2019-08-29 19:56:00 -0700
tags:   study-cs machien-learning
---

## 本系列的其它文章

- [斯坦福机器学习课程笔记（Week 1）]({% post_url 2019-06-25-stanford-ml-wk1 %})
- [斯坦福机器学习课程笔记（Week 2）]({% post_url 2019-07-05-stanford-ml-wk2 %})
- [斯坦福机器学习课程笔记（Week 3）]({% post_url 2019-07-13-stanford-ml-wk3 %})
- [斯坦福机器学习课程笔记（Week 4）]({% post_url 2019-07-15-stanford-ml-wk4 %})
- [斯坦福机器学习课程笔记（Week 5）]({% post_url 2019-07-25-stanford-ml-wk5 %})
- [斯坦福机器学习课程笔记（Week 6）]({% post_url 2019-08-01-stanford-ml-wk6 %})
- [斯坦福机器学习课程笔记（Week 7）]({% post_url 2019-08-05-stanford-ml-wk7 %})
- [斯坦福机器学习课程笔记（Week 8）]({% post_url 2019-08-12-stanford-ml-wk8 %})
- [斯坦福机器学习课程笔记（Week 9）]({% post_url 2019-08-20-stanford-ml-wk9 %})
- [斯坦福机器学习课程笔记（Week 10）]({% post_url 2019-08-29-stanford-ml-wk10 %})
- **斯坦福机器学习课程笔记（Week 11）**

## 应用：光学字符识别（OCR）

### OCR系统工作流程

1. 文字检测
2. 将文字分隔成字符
3. 字符分类

![image-20190829200618547](/assets/2019-08-29-stanford-ml-wk11/image-20190829200618547.png)

有时我们称这种工作流程为“流水线（Pipeline）”。有了流水线，我们可以更好地将整个机器学习系统的构建任务分配给不同的人。

### Sliding Windows

让我们先用一个与文字检测类似，但更简单的问题，行人检测，来理解什么是Sliding Windows。

对于行人检测，我们可以将训练集标准化为$$82\times 36$$的图像，然后若图中有行人，标记为$$y=1$$，无人则标记为$$y=0$$。最后利用神经网络或者其它机器学习算法进行训练即可。

![image-20190829201431978](/assets/2019-08-29-stanford-ml-wk11/image-20190829201431978.png)

训练好模型后，我们怎么将它运用到一张新的图片上呢？我们可以从图片的最左上角开始，用一个同尺寸的框，从左往右，从上往下扫描，完成一次扫描后，加大框的尺寸，回到左上角，继续从左往右从上往下扫描，如此反复，最后就会得到检测到的行人。

![image-20190829201845302](/assets/2019-08-29-stanford-ml-wk11/image-20190829201845302.png)

文字检测也类似，我们可以用类似的方法准备数据并训练模型。

![image-20190829201957478](/assets/2019-08-29-stanford-ml-wk11/image-20190829201957478.png)

用类似的扫描法，我们可以用得到有文字的区域（下图中左下角的小图中的白色部分）。不过，对于文字识别，我们通常还会进行“expansion”，就是将附近颜色为白色的像素，也设为白色（下图右下角小图为结果）。

![image-20190829202406327](/assets/2019-08-29-stanford-ml-wk11/image-20190829202406327.png)

在得到文字区域后，我们就可以将这些区域裁剪出来，送入管道的下一部分，将字符从文字中分隔出来。在这一步，我们设存在两个字符分割区域的图像为$$y=1$$，不存在的为$$y=0$$，我们可以得到如下训练集

![image-20190829202639285](/assets/2019-08-29-stanford-ml-wk11/image-20190829202639285.png)

然后，我们同样可以使用sliding windows，得到所有的字符分隔区域。

![image-20190829202749073](/assets/2019-08-29-stanford-ml-wk11/image-20190829202749073.png)

最后，我们就能得到单个的字符，可以对单个字符进行识别了。

### 人工数据合成（Artificial Data Synthesis）

假设我们的数据不够用，我们可以考虑采用人工合成的数据来扩充训练集。下图的右侧数据是由背景加上不同的字体并进行一些扭曲、旋转、模糊等变换后生成的数据。这一类人工数据合成属于从头开始制造新的训练数据。

![image-20190829203301933](/assets/2019-08-29-stanford-ml-wk11/image-20190829203301933.png)

此外，我们也可以从已有的数据中生成新的数据，比如说对已有的图片进行各种变换以生成新数据。对于语音识别的问题来讲，就是将原本的人生，加上各种效果（滤波、混响等），以生成新的数据。

![image-20190829203504163](/assets/2019-08-29-stanford-ml-wk11/image-20190829203504163.png)

但是，吴教授这里指出，对数据加入纯粹的随机噪声意义不大。此外，我们应该在取得一个低偏差的分类器后，再进行数据集的扩充（因为加入新数据无法解决高偏差问题）。还有就是在尝试人工合成数据之前，可以先想想，获取多10倍的数据有多难，到底是用人工数据合成法，还是手动收集并分类（可以考虑一下手工收集分类所耗费的时间，吴教授指出，实际上手工收集并分类的耗时并没有想象中的那么多）。

### Ceiling Analysis

通过Ceiling Analysis，我们可以确定我们整个流水线中的关键部分在哪里，并帮助我们改进整个机器学习流水线。

![image-20190829205817560](/assets/2019-08-29-stanford-ml-wk11/image-20190829205817560.png)

比如说对于上面这一个OCR流水线，在全自动模式下准确率是72%。我们可以通过人工检测文字区域的方式，给第二部分提供100%准确率的输入。此时，总的准确率为89%。同样，我们手工分隔每个字符，给第三部分提供100%准确的输入，此时，总的准确率为90%。

![image-20190829210138298](/assets/2019-08-29-stanford-ml-wk11/image-20190829210138298.png)

此时我们就能发现，这个模型的短板目前主要在文字识别上，其次是字符识别。因为手动进行文字识别能提高17%的整体准确度，手动进行字符识别能提升10%，但是手动进行字符分隔只能提升1%。

## 结束语

个人认为这一套公开课比较适合像我这种有基本的数学、统计和编程基础，但是对机器学习没有任何了解的人的入门课程。美中不足的是我认为吴教授略过了很多数学原理的讲解，当然他可能是出于课程难度的考虑，不过我认为就算对课程难度有所顾虑，也可以提供一些可选的数学原理，不一定是视频课程，阅读资料也行。不过还是那句“师父领进门，修行靠个人”就是了。

[![Certificate](/assets/2019-08-29-stanford-ml-wk11/Certificate.png)](https://coursera.org/verify/QSSE5MKMFMUA)
